{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971fc069-0c36-4aac-b0a0-0f07074e6120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO object detector - trained OBJECTS, in this case the javelin (best.pt in this repository): \n",
    "\n",
    "# === Import Libraries ===\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import cv2\n",
    "import gc\n",
    "import numpy as np\n",
    "np.float = np.float64\n",
    "import psutil\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO\n",
    "from torchreid.utils import FeatureExtractor\n",
    "import yaml\n",
    "\n",
    "# Load class names from dataset from training.yaml\n",
    "with open(\"/Users/Christian/Downloads/Javelin training/YOLO javelin_2/yolo_dataset/dataset.yaml\", \"r\") as file:\n",
    "    dataset_config = yaml.safe_load(file)\n",
    "class_names = dataset_config[\"names\"]\n",
    "\n",
    "\n",
    "# === Ensure Torch Uses Metal (MPS) ===\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using {device} for computation.\")\n",
    "\n",
    "# === User Input for Paths ===\n",
    "input_folder = \"/Users/Christian/Downloads/Javelin training/analysis\"\n",
    "output_folder = os.path.join(input_folder, \"YOLO_Object\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "video_files = [f for f in os.listdir(input_folder) if f.lower().endswith(\".mp4\")]\n",
    "\n",
    "# === Initialize YOLOv11 ===\n",
    "body_detector = YOLO(\"/Users/Christian/Downloads/Javelin training/YOLO javelin_2/yolo_dataset/results/yolo_train2/weights/best.pt\")\n",
    "print(\"‚úÖ Custom YOLOv11 Model loaded.\")\n",
    "\n",
    "# === Initialize Torchreid (OSNet) ===\n",
    "extractor = FeatureExtractor(\n",
    "    model_name='osnet_x1_0',\n",
    "    model_path=\"/Users/Christian/Torch ReID/osnet_x1_0_msmt17.pth\",\n",
    "    device=\"mps\"\n",
    ")\n",
    "print(\"‚úÖ OSNet ReID Model Initialized on MPS.\")\n",
    "\n",
    "# === Add BoT-SORT Tracker ===\n",
    "sys.path.append(\"/Users/Christian/Christian Home Drive/Christian/Projekte/CURRENTLY RUNNING PROJECTS/CV and NLP/Python_codes and apps/sort/BoT-SORT\")\n",
    "from tracker.bot_sort_reid import BoTSORT\n",
    "import argparse\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    track_high_thresh=0.7,\n",
    "    track_low_thresh=0.04,\n",
    "    new_track_thresh=0.24,\n",
    "    track_buffer=7000,\n",
    "    max_age=7000,\n",
    "    n_init=4,\n",
    "    match_thresh=0.93,\n",
    "    mot20=False,\n",
    "    proximity_thresh=0.35,\n",
    "    appearance_thresh=0.85,\n",
    "    cmc_method=\"sparseOptFlow\",\n",
    "    name=\"BoT-SORT\",\n",
    "    ablation=False,\n",
    "    with_reid=True,\n",
    "    lambda_=0.98,\n",
    "    use_byte=False,\n",
    "    device='mps',\n",
    "    imgsz=640\n",
    ")\n",
    "\n",
    "# === Process Videos ===\n",
    "for video_file in video_files:\n",
    "    input_path = os.path.join(input_folder, video_file)\n",
    "    csv_path = os.path.join(output_folder, f\"{os.path.splitext(video_file)[0]}.csv\")\n",
    "    print(f\"\\nüé¨ Now processing: {video_file}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Could not open {input_path}\")\n",
    "        continue\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    progress_bar = tqdm(total=total_frames, desc=\"Processing Frames\", unit=\"frame\", leave=False)\n",
    "\n",
    "    frame_num = 0\n",
    "    columns = ['Frame', 'Track_ID', 'Label', 'X1', 'Y1', 'X2', 'Y2']\n",
    "    with open(csv_path, 'w') as f:\n",
    "        f.write(','.join(columns) + '\\n')\n",
    "\n",
    "    tracker = BoTSORT(args, frame_rate=fps)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_num += 1\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            if frame_num % 100 == 0 and psutil.virtual_memory().percent > 80:\n",
    "                gc.collect()\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "            results = body_detector(frame, conf=0.20, iou=0.55, verbose=False, imgsz=1024)\n",
    "\n",
    "            tracked_bodies, body_crops, labels = [], [], []\n",
    "\n",
    "            for result in results:\n",
    "                for box in result.boxes:\n",
    "                    conf = box.conf[0].item()\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    label = class_names[cls_id] if cls_id < len(class_names) else \"unknown\"\n",
    "                    if conf > 0.20:\n",
    "                        tracked_bodies.append([x1, y1, x2, y2, conf])\n",
    "                        labels.append(label)\n",
    "                        crop = frame[y1:y2, x1:x2]\n",
    "                        if crop.shape[0] > 2 and crop.shape[1] > 2:\n",
    "                            crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "                            body_crops.append(crop_rgb)\n",
    "\n",
    "            if len(body_crops) == 0:\n",
    "                continue\n",
    "\n",
    "            embeddings = extractor(body_crops)\n",
    "            body_features = np.array([e.cpu().numpy() for e in embeddings])\n",
    "            tracked_bodies_np = np.array(tracked_bodies, dtype=np.float64).reshape(-1, 5)\n",
    "\n",
    "            try:\n",
    "                tracked_results = tracker.update(tracked_bodies_np, frame, body_features)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Tracking failed on frame {frame_num}: {e}\")\n",
    "                continue\n",
    "\n",
    "            for i, track in enumerate(tracked_results):\n",
    "                x1, y1, w, h = map(int, track.tlwh)\n",
    "                x2, y2 = x1 + w, y1 + h\n",
    "                track_id = int(track.track_id)\n",
    "                label = labels[i] if i < len(labels) else \"unknown\"\n",
    "                with open(csv_path, 'a') as f:\n",
    "                    f.write(f\"{frame_num},{track_id},{label},{x1},{y1},{x2},{y2}\\n\")\n",
    "\n",
    "    cap.release()\n",
    "    progress_bar.close()\n",
    "    print(f\"‚úÖ Finished {video_file}\")\n",
    "\n",
    "print(\"\\nüéâ All sessions processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
