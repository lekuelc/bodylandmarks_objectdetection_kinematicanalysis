{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f98e6-66fc-4c5a-ac7f-6a8859c5ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do two steps:\n",
    "# Step 1: Merge landmark detection (from RTM Pose) with Person detector (ID):\n",
    "\n",
    "# REASSIGNMENT === UPDATED SCRIPT: Add Full Skeleton ===\n",
    "# === FINAL CLEAN SCRIPT: Stable ID Assignment + Pose Matching + True Reassignment (Skeleton to Skeleton) ===\n",
    "\n",
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# === SETTINGS ===\n",
    "MATCH_THRESHOLD_FRAME = 150          # Pixel-based threshold if not normalizing\n",
    "USE_NORMALIZED_DISTANCE = True       # Switch for normalized matching, otherwise fixed distance matching\n",
    "NORMALIZED_MATCH_THRESHOLD = 0.3     # Threshold if normalizing distances\n",
    "\n",
    "# === LOAD VIDEO FILES ===\n",
    "base_folder = Path(\"/Users/Christian/Downloads/Microadaptive Teaching Dritter Teil - LAs/Marlon/Erste Sitzung/YOLO\")\n",
    "video_files = list(base_folder.glob(\"*.mp4\")) + list(base_folder.glob(\"*.MP4\"))\n",
    "\n",
    "# === MAIN LOOP: PROCESS EACH VIDEO ===\n",
    "for video_path in video_files:\n",
    "    print(f\"\\nðŸŽ¥ Processing video: {video_path.name}\")\n",
    "\n",
    "    INPUT_PATH = video_path\n",
    "\n",
    "    # === LOAD TRACKING DATA (Bounding Boxes) ===\n",
    "    tracking_df = pd.read_csv(INPUT_PATH.parent / \"YOLO\" / (INPUT_PATH.stem + \".csv\"))\n",
    "\n",
    "    # === LOAD POSE ESTIMATION DATA (Skeletons) ===\n",
    "    pose_df = pd.read_csv(INPUT_PATH.parent / \"DLC\" / (INPUT_PATH.stem + \"_predictions.csv\"), low_memory=False)\n",
    "\n",
    "    # === PREPARE POSE DATAFRAME ===\n",
    "    multi_index = pd.MultiIndex.from_arrays(pose_df.iloc[0:3].values, names=[\"individual\", \"bodypart\", \"coord\"])\n",
    "    pose_data_cleaned = pose_df.iloc[3:].copy()\n",
    "    pose_data_cleaned.columns = multi_index\n",
    "    pose_data_cleaned.reset_index(drop=True, inplace=True)\n",
    "    pose_data_cleaned[\"Frame\"] = pose_data_cleaned.index.astype(int)\n",
    "\n",
    "    # === DETECT BODY PARTS (skip non-body columns) ===\n",
    "    bodyparts = pose_data_cleaned.columns.get_level_values(\"bodypart\").unique()\n",
    "    bodyparts = [bp for bp in bodyparts if bp not in [\"Frame\", \"scorer\"]]\n",
    "\n",
    "    # === FINAL DATA COLLECTOR ===\n",
    "    final_data = []\n",
    "\n",
    "    # === FRAME-BY-FRAME PROCESSING ===\n",
    "    for frame_idx, pose_row in tqdm(pose_data_cleaned.iterrows(), total=len(pose_data_cleaned), desc=f\"Processing {INPUT_PATH.stem}\"):\n",
    "        frame_num = int(pose_row[\"Frame\"].iloc[0] if isinstance(pose_row[\"Frame\"], pd.Series) else pose_row[\"Frame\"])\n",
    "        frame_boxes = tracking_df[tracking_df.Frame == frame_num]\n",
    "\n",
    "        # === EXTRACT ALL SKELETON CENTERS IN THIS FRAME ===\n",
    "        skeleton_centers = {}\n",
    "        individuals = pose_row.index.get_level_values(\"individual\").unique()\n",
    "        individuals = [ind for ind in individuals if ind.startswith(\"idv_\")]\n",
    "\n",
    "        for ind in individuals:\n",
    "            keypoints = []\n",
    "            for bp in bodyparts:\n",
    "                try:\n",
    "                    x = float(pose_row[(ind, bp, \"x\")])\n",
    "                    y = float(pose_row[(ind, bp, \"y\")])\n",
    "                    if pd.notna(x) and pd.notna(y):\n",
    "                        keypoints.append((x, y))\n",
    "                except:\n",
    "                    continue\n",
    "            if keypoints:\n",
    "                cx, cy = np.mean(keypoints, axis=0)  # Compute mean x, mean y = skeleton center\n",
    "                skeleton_centers[ind] = (cx, cy)\n",
    "\n",
    "        # === MATCH EACH BOUNDING BOX TO NEAREST SKELETON ===\n",
    "        for _, box in frame_boxes.iterrows():\n",
    "            x_center = (box.X1 + box.X2) / 2\n",
    "            y_center = (box.Y1 + box.Y2) / 2\n",
    "            pid = int(box.Person_ID)\n",
    "\n",
    "            best_match = None\n",
    "            min_distance = float('inf')\n",
    "\n",
    "            for skel_id, (cx, cy) in skeleton_centers.items():\n",
    "                center_distance = np.linalg.norm(np.array([cx, cy]) - np.array([x_center, y_center]))\n",
    "\n",
    "                # === OPTIONAL: Normalize distance by bounding box size ===\n",
    "                if USE_NORMALIZED_DISTANCE:\n",
    "                    bbox_width = box.X2 - box.X1\n",
    "                    bbox_height = box.Y2 - box.Y1\n",
    "                    avg_bbox_size = (bbox_width + bbox_height) / 2\n",
    "                    if avg_bbox_size > 0:\n",
    "                        center_distance /= avg_bbox_size\n",
    "\n",
    "                threshold = NORMALIZED_MATCH_THRESHOLD if USE_NORMALIZED_DISTANCE else MATCH_THRESHOLD_FRAME\n",
    "\n",
    "                # === KEEP CLOSEST SKELETON UNDER THRESHOLD ===\n",
    "                if center_distance < min_distance and center_distance < threshold:\n",
    "                    best_match = skel_id\n",
    "                    min_distance = center_distance\n",
    "\n",
    "            # === SAVE MATCH INFORMATION ===\n",
    "            data = {\n",
    "                \"Frame\": frame_num,\n",
    "                \"Old_ID\": pid,\n",
    "                \"New_ID\": pid,\n",
    "                \"X1\": box.X1,\n",
    "                \"Y1\": box.Y1,\n",
    "                \"X2\": box.X2,\n",
    "                \"Y2\": box.Y2,\n",
    "            }\n",
    "\n",
    "            if best_match:\n",
    "                skel_num = best_match.split(\"_\")[1]\n",
    "                for bp in bodyparts:\n",
    "                    x = pose_row.get((f\"idv_{skel_num}\", bp, \"x\"), np.nan)\n",
    "                    y = pose_row.get((f\"idv_{skel_num}\", bp, \"y\"), np.nan)\n",
    "                    conf = pose_row.get((f\"idv_{skel_num}\", bp, \"likelihood\"), np.nan)\n",
    "                    data[f\"{bp}_x\"] = x\n",
    "                    data[f\"{bp}_y\"] = y\n",
    "                    data[f\"{bp}_conf\"] = conf\n",
    "\n",
    "            final_data.append(data)\n",
    "\n",
    "    # === SAVE FINAL CORRECTED CSV ===\n",
    "    final_df = pd.DataFrame(final_data)\n",
    "    final_df = final_df.sort_values([\"Frame\", \"New_ID\"])\n",
    "    final_df.drop(columns=[\"bodyparts_x\", \"bodyparts_y\", \"bodyparts_conf\", \"_x\", \"_y\", \"_conf\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    OUTPUT_FOLDER = INPUT_PATH.parent / \"corrected\"\n",
    "    OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    output_csv_name = f\"{INPUT_PATH.stem}_corrected.csv\"\n",
    "    final_df.to_csv(OUTPUT_FOLDER / output_csv_name, index=False)\n",
    "\n",
    "    print(\"\\u2705 Final corrected CSV saved for:\", video_path.name)\n",
    "\n",
    "print(\"\\nðŸŽ‰ All sessions processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32dab4-62fc-4589-b1d2-daf90b1ea63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2:  Merge landmark and ID detection with object detection: \n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === PATHS ===\n",
    "main_folder = Path(\"/Users/Christian/Downloads/Javelin training/analysis/corrected\")\n",
    "object_folder = Path(\"/Users/Christian/Downloads/Javelin training/analysis/YOLO_Object\")\n",
    "merged_folder = main_folder / \"with_objects\"\n",
    "merged_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === PROCESSING LOOP ===\n",
    "for corrected_file in main_folder.glob(\"*_corrected.csv\"):\n",
    "    base_name = corrected_file.stem.replace(\"_corrected\", \"\")\n",
    "    object_file = object_folder / f\"{base_name}.csv\"\n",
    "\n",
    "    if not object_file.exists():\n",
    "        print(f\"Skipping {base_name} â€” no object file found.\")\n",
    "        continue\n",
    "\n",
    "    # Load both dataframes\n",
    "    df_people = pd.read_csv(corrected_file)\n",
    "    df_object = pd.read_csv(object_file)\n",
    "\n",
    "    # Compute center points\n",
    "    df_object[\"center_x\"] = (df_object[\"X1\"] + df_object[\"X2\"]) / 2\n",
    "    df_object[\"center_y\"] = (df_object[\"Y1\"] + df_object[\"Y2\"]) / 2\n",
    "\n",
    "    # Pivot: one row per frame, columns like Tip_center_x, Handle_center_y, etc.\n",
    "    # Keep only needed columns\n",
    "    df_object_slim = df_object[[\"Frame\", \"Label\", \"X1\", \"Y1\", \"X2\", \"Y2\", \"center_x\", \"center_y\"]]\n",
    "    \n",
    "    # Pivot: one row per frame, columns like Tip_X1, Tip_center_x, etc.\n",
    "    df_object_pivot = df_object_slim.pivot_table(\n",
    "        index=\"Frame\",\n",
    "        columns=\"Label\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Flatten multi-index columns\n",
    "    df_object_pivot.columns = [f\"{label}_{coord}\" for coord, label in df_object_pivot.columns]\n",
    "    df_object_pivot.reset_index(inplace=True)\n",
    "\n",
    "    # Merge person + object center info\n",
    "    df_merged = df_people.merge(df_object_pivot, on=\"Frame\", how=\"left\")\n",
    "\n",
    "    # Save to new folder\n",
    "    out_path = merged_folder / f\"{base_name}_merged.csv\"\n",
    "    df_merged.to_csv(out_path, index=False)\n",
    "    print(f\"âœ… Merged and saved: {out_path.name}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All sessions processed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (face)",
   "language": "python",
   "name": "face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
