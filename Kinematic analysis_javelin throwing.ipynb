{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0270c-4f7e-4a8c-8fcf-1677a5f2a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import time\n",
    "from pathlib import Path\n",
    "import atexit\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.stats import linregress\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.ndimage import label \n",
    "import base64\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# ==== CONFIGURATION ====\n",
    "INPUT_DIR = Path(\"/Users/Christian/Downloads/Javelin_Bad Krozingen und Neustadt_data\")\n",
    "OUTPUT_FILE = INPUT_DIR / \"kinematic_summary.csv\"\n",
    "csv_files = list(INPUT_DIR.glob(\"*_merged.csv\"))\n",
    "all_results = []\n",
    "\n",
    "\n",
    "ONLY_LONGEST_ID = True  # Set to False to process all IDs, True for only the one with max rows\n",
    "\n",
    "\n",
    "\n",
    "# PARAMETERS:\n",
    "# For javelin leaves the hand: \n",
    "WHEN_START_MS = 800 # in milliseconds\n",
    "MIN_DELTA = 160\n",
    "MIN_FRACTION = 0.55\n",
    "MIN_SUSTAIN_SEC = 0.25  # duration in seconds\n",
    "\n",
    "\n",
    "THRESHOLD = 10  # how big should the rise be?\n",
    "\n",
    "\n",
    "# Detecting peaks and troughs for foot-strike:\n",
    "PROMINENCE = 3\n",
    "DISTANCE_MS = 300\n",
    "        \n",
    "\n",
    "# Stride length: \n",
    "STEP_RATIO = 1\n",
    "\n",
    "# For Footstrike: \n",
    "MAX_SHIFT_MS = 400  # adjust if needed\n",
    "Y_PROMINENCE = 1  # controls how \"sharp\" a trough must be\n",
    "\n",
    "\n",
    "# Parameters for if arm is outstretched during the run-up: \n",
    "ONSET_OFFSET_MS = 150\n",
    "OFFSET_BEFORE_RELEASE_MS = 100\n",
    "WINDOW_BEFORE_RELEASE_MS = 2500\n",
    "REQUIRED_ABOVE_ANGLE_MS = 150\n",
    "THRESHOLD_ANGLE = 150\n",
    "MIN_MAX_DURATION_FRAMES = 2\n",
    "\n",
    "\n",
    "# Parameters for stopping:\n",
    "STOP_WIN_MS = 300\n",
    "STOP_RATIO_THRESHOLD = 0.55\n",
    "\n",
    "time_window_ms = 400  # Analyze steps at xx ms after release (change as needed)\n",
    "\n",
    "# Functions: \n",
    "def smooth_series(series, window_size=5):\n",
    "    return pd.Series(series).rolling(window=window_size, min_periods=1, center=True).mean().tolist()\n",
    "\n",
    "\n",
    "\n",
    "# low butterworth filter\n",
    "def butter_lowpass_filter(signal, cutoff=5, order=1, fs=30):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "    \n",
    "\n",
    "def calculate_angle(ax, ay, bx, by, cx, cy):\n",
    "    if any(pd.isna([ax, ay, bx, by, cx, cy])):\n",
    "        return np.nan\n",
    "    v1, v2 = np.array([ax - bx, ay - by]), np.array([cx - bx, cy - by])\n",
    "    norm = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    if norm == 0:\n",
    "        return np.nan\n",
    "    angle = np.arccos(np.clip(np.dot(v1, v2) / norm, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def frame_diff(x, y):\n",
    "    return [0] + [np.linalg.norm([x[i] - x[i - 1], y[i] - y[i - 1]]) for i in range(1, len(x))]\n",
    "\n",
    "\n",
    "\n",
    "# Distance function\n",
    "def dist(wrist_x, wrist_y, obj_x, obj_y):\n",
    "    if any(pd.isna([wrist_x, wrist_y, obj_x, obj_y])):\n",
    "        return np.nan\n",
    "    return np.linalg.norm([wrist_x - obj_x, wrist_y - obj_y])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Split session_name into components\n",
    "def parse_session_name(session_name):\n",
    "    parts = session_name.split(\"_\")\n",
    "    if len(parts) == 5:\n",
    "        school, class_id, condition, subj_id, throw_nr = parts\n",
    "    elif len(parts) == 4:\n",
    "        school = None\n",
    "        class_id, condition, subj_id, throw_nr = parts\n",
    "    else:\n",
    "        return None, None, None, None, None\n",
    "    try:\n",
    "        throw_nr = int(str(throw_nr).lstrip(\"0\"))\n",
    "    except Exception:\n",
    "        throw_nr = None\n",
    "    return school, class_id, condition, subj_id, throw_nr\n",
    "\n",
    "\n",
    "\n",
    "def border_nanmean(arr, n=2, window_size=8):\n",
    "    \"\"\"Mean of up to n closest valid values in first/last window_size.\"\"\"\n",
    "    arr = np.array(arr)\n",
    "    # First part\n",
    "    first = arr[:window_size]\n",
    "    first_valid = first[np.isfinite(first)]\n",
    "    if len(first_valid) >= n:\n",
    "        first_border_mean = np.mean(first_valid[:n])\n",
    "    elif len(first_valid) > 0:\n",
    "        first_border_mean = np.mean(first_valid)\n",
    "    else:\n",
    "        first_border_mean = np.nan\n",
    "    # Last part\n",
    "    last = arr[-window_size:]\n",
    "    last_valid = last[np.isfinite(last)]\n",
    "    if len(last_valid) >= n:\n",
    "        last_border_mean = np.mean(last_valid[-n:])\n",
    "    elif len(last_valid) > 0:\n",
    "        last_border_mean = np.mean(last_valid)\n",
    "    else:\n",
    "        last_border_mean = np.nan\n",
    "    return first_border_mean, last_border_mean\n",
    "\n",
    "\n",
    "def find_sustained_increases(\n",
    "        signal, deriv, threshold, min_sustain=100, min_delta=MIN_DELTA, min_fraction=MIN_FRACTION, min_start_ms=WHEN_START_MS):\n",
    "    \"\"\"\n",
    "    min_sustain: number of frames\n",
    "    min_start_ms: where to start searching, in milliseconds (converted to frames)\n",
    "    fps: frames per second\n",
    "    \"\"\"\n",
    "    min_start = int(round(min_start_ms * fps / 1000))\n",
    "    i = min_start\n",
    "    N = len(signal)\n",
    "    while i <= N - min_sustain - 1:\n",
    "        if deriv[i] > threshold:\n",
    "            window = signal[i:i+min_sustain+1]\n",
    "            start_mean, end_mean = border_nanmean(window, n=2, window_size=5)\n",
    "            if np.isnan(start_mean) or np.isnan(end_mean):\n",
    "                i += 1\n",
    "                continue\n",
    "            diffs = np.diff(window)\n",
    "            fraction_increasing = np.mean(diffs > 0)\n",
    "            sustained = fraction_increasing >= min_fraction\n",
    "            total_increase = end_mean - start_mean\n",
    "            if sustained and total_increase > min_delta:\n",
    "                return np.array([i])\n",
    "        i += 1\n",
    "    return np.array([])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def refine_to_next_ankle_y_maximum(\n",
    "    coords_df,\n",
    "    candidate_indices,\n",
    "    side,\n",
    "    fps,\n",
    "    MAX_SHIFT_MS,\n",
    "    Y_PROMINENCE=0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    For each candidate frame, search forward up to MAX_SHIFT_MS in the ankle_y signal\n",
    "    for the NEXT local maximum (peak). If none is found, keep the original index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords_df : pd.DataFrame\n",
    "        DataFrame containing pose data.\n",
    "    candidate_indices : list[int] or np.array[int]\n",
    "        Frame indices of initial candidates.\n",
    "    side : str\n",
    "        'left' or 'right'\n",
    "    fps : float\n",
    "        Frames per second.\n",
    "    MAX_SHIFT_MS : int\n",
    "        Max window after candidate to search (in milliseconds).\n",
    "    Y_PROMINENCE : float\n",
    "        Optional minimum prominence for maxima.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[int] : Refined frame indices (each being either the next peak or original).\n",
    "    \"\"\"\n",
    "    ankle_y = coords_df[f\"{side}_ankle_y\"].values\n",
    "    max_shift = int(np.round(MAX_SHIFT_MS * fps / 1000))\n",
    "    N = len(ankle_y)\n",
    "    refined_indices = []\n",
    "\n",
    "    for idx in candidate_indices:\n",
    "        # Define the window: starts just after idx to idx+max_shift (inclusive)\n",
    "        start = idx + 1\n",
    "        end = min(idx + max_shift, N - 1)\n",
    "        if start > end:\n",
    "            # If window is empty, just keep idx\n",
    "            refined_indices.append(idx)\n",
    "            continue\n",
    "        segment = ankle_y[start:end+1]\n",
    "        peaks, _ = find_peaks(segment, prominence=Y_PROMINENCE)\n",
    "        if len(peaks) > 0:\n",
    "            # peaks[0] is relative to start, so add to start (which is idx+1)\n",
    "            refined_indices.append(start + peaks[0])\n",
    "        else:\n",
    "            refined_indices.append(idx)\n",
    "    return refined_indices\n",
    "    \n",
    "\n",
    "\n",
    "def get_video_fps(video_path):\n",
    "    if not video_path.exists():\n",
    "        print(f\"Video file not found: {video_path}\")\n",
    "        return None\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    # Strict: Only accept FPS > 0 and reasonable (e.g., 10 < fps < 300)\n",
    "    if not fps or fps < 10 or fps > 300:\n",
    "        print(f\"⚠️ Could not read a valid FPS from {video_path} (got: {fps}). Skipping file.\")\n",
    "        return None\n",
    "    return fps\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Loop through files: \n",
    "for csv_file in tqdm(csv_files, desc=\"Processing CSVs\"):\n",
    "    session_name = csv_file.stem.replace(\"_merged\", \"\")\n",
    "\n",
    "    school, class_id, condition, subj_id, throw_nr = parse_session_name(session_name)\n",
    "\n",
    "    video_path = csv_file.parent.parent.parent / f\"{session_name}.mp4\"\n",
    "    fps = get_video_fps(video_path)\n",
    "\n",
    "    if fps is None:\n",
    "        print(f\"⚠️ Skipping {session_name} (no video/fps)\")\n",
    "        continue\n",
    "\n",
    "    min_sustain = int(fps * MIN_SUSTAIN_SEC)\n",
    "\n",
    "        \n",
    "    df = pd.read_csv(csv_file)\n",
    "    person_ids = df[\"New_ID\"].unique()\n",
    "\n",
    "    # Only take the longest ID:\n",
    "    if ONLY_LONGEST_ID:\n",
    "        id_counts = df[\"New_ID\"].value_counts()\n",
    "        # Remove both int and string representations of -1\n",
    "        id_counts = id_counts[~id_counts.index.isin([-1, \"-1\"])]\n",
    "        if len(id_counts) == 0:\n",
    "            print(f\"⚠️ No valid IDs in {csv_file.name}. Skipping.\")\n",
    "            continue\n",
    "        longest_id = id_counts.idxmax()\n",
    "        person_ids = [longest_id]\n",
    "    \n",
    "    \n",
    "    for person_id in person_ids:\n",
    "        person_df = df[df[\"New_ID\"] == person_id].copy()\n",
    "        if person_df.empty:\n",
    "            continue\n",
    "\n",
    "        # --- Interpolate missing frames only for small gaps (e.g., <= 0.25 seconds) ---\n",
    "        person_df = person_df.sort_values(\"Frame\").reset_index(drop=True)\n",
    "        visible_frames = sorted(person_df[\"Frame\"].dropna().unique())\n",
    "        fps = float(fps)  # Make sure you have fps defined (set it above)\n",
    "        max_gap_frames = int(fps * 0.25)  # interpolate gaps up to 0.25 seconds\n",
    "        \n",
    "        interpolated_rows = []\n",
    "        for i in range(1, len(visible_frames)):\n",
    "            prev_f = visible_frames[i - 1]\n",
    "            curr_f = visible_frames[i]\n",
    "            gap = curr_f - prev_f\n",
    "        \n",
    "            if 1 < gap <= max_gap_frames:\n",
    "                df_prev = person_df[person_df[\"Frame\"] == prev_f].iloc[0]\n",
    "                df_next = person_df[person_df[\"Frame\"] == curr_f].iloc[0]\n",
    "        \n",
    "                for f in range(prev_f + 1, curr_f):\n",
    "                    alpha = (f - prev_f) / (curr_f - prev_f)\n",
    "                    interpolated = {\"Frame\": f, \"New_ID\": person_id}\n",
    "                    for col in person_df.columns:\n",
    "                        if col.endswith(\"_x\") or col.endswith(\"_y\") or col.endswith(\"_conf\"):\n",
    "                            val_prev = df_prev[col]\n",
    "                            val_next = df_next[col]\n",
    "                            if pd.notna(val_prev) and pd.notna(val_next):\n",
    "                                interpolated[col] = (1 - alpha) * val_prev + alpha * val_next\n",
    "                            else:\n",
    "                                interpolated[col] = np.nan\n",
    "                        elif col not in interpolated:\n",
    "                            interpolated[col] = df_prev[col]\n",
    "                    interpolated_rows.append(interpolated)\n",
    "        \n",
    "        if interpolated_rows:\n",
    "            person_df = pd.concat([person_df, pd.DataFrame(interpolated_rows)], ignore_index=True)\n",
    "        \n",
    "        person_df = person_df.sort_values(\"Frame\").reset_index(drop=True)\n",
    "        \n",
    "        # (optional) guarantee you have all frames (if needed for downstream code)\n",
    "        min_frame = int(person_df[\"Frame\"].min())\n",
    "        max_frame = int(person_df[\"Frame\"].max())\n",
    "        all_frames = pd.DataFrame({\"Frame\": np.arange(min_frame, max_frame + 1)})\n",
    "        plot_df = pd.merge(all_frames, person_df, on=\"Frame\", how=\"left\", sort=True).reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        # Smoothing the signals: \n",
    "        # === Step 1: Setup ===\n",
    "        joint_names = [\"ankle\", \"knee\", \"hip\", \"shoulder\", \"elbow\", \"wrist\"]\n",
    "        sides = [\"left\", \"right\"]\n",
    "        axes = [\"x\", \"y\"]\n",
    "        \n",
    "        # Initialize dictionary to collect all coordinate time series\n",
    "        coords = {f\"{side}_{joint}_{axis}\": [] for side in sides for joint in joint_names for axis in axes}\n",
    "        \n",
    "        # === Step 2: Fill from plot_df row by row ===\n",
    "        for row in plot_df.itertuples():\n",
    "            row_data = row._asdict()\n",
    "            for key in coords:\n",
    "                coords[key].append(row_data.get(key, np.nan))\n",
    "\n",
    "        # === Interpolate missing values, but SKIP javelin parts ===\n",
    "        for key in coords:\n",
    "            arr = np.array(coords[key], dtype='float')\n",
    "            s = pd.Series(arr)\n",
    "            if s.isnull().any():\n",
    "                coords[key] = s.interpolate(method='linear', limit_direction='both').tolist()\n",
    "            else:\n",
    "                coords[key] = arr.tolist()\n",
    "    \n",
    "        \n",
    "        # Define joint motion types\n",
    "        slow_joints = [\"hip\", \"shoulder\"]\n",
    "        fast_joints = [\"ankle\", \"wrist\", \"elbow\", \"Tail\", \"Handle\", \"Tip\"]\n",
    "        \n",
    "        # Apply Butterworth filter with joint-specific cutoffs\n",
    "        for key in coords:\n",
    "            signal = coords[key]\n",
    "            \n",
    "            if len(signal) > 5 and not all(pd.isna(signal)):\n",
    "                joint_name = key.split(\"_\")[1] if \"_\" in key else key  # Extract joint name\n",
    "        \n",
    "                # Select cutoff frequency based on joint type\n",
    "                if any(j in joint_name for j in slow_joints):\n",
    "                    cutoff = 3\n",
    "                elif any(j in joint_name for j in fast_joints):\n",
    "                    cutoff = 7\n",
    "                else:\n",
    "                    cutoff = 5\n",
    "        \n",
    "                # Try filtering\n",
    "                try:\n",
    "                    coords[key] = butter_lowpass_filter(np.array(signal), cutoff=cutoff, order=1, fs=fps)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Skipping filter for {key} due to error: {e}\")\n",
    "        \n",
    "        # === Step 4: Convert to DataFrame ===\n",
    "        coords_df = pd.DataFrame(coords)\n",
    "        \n",
    "        # Optionally add frame column if needed\n",
    "        coords_df[\"frame\"] = plot_df[\"Frame\"].values\n",
    "        frame_to_row = {frame: i for i, frame in enumerate(coords_df[\"frame\"])}\n",
    "        \n",
    "        \n",
    "        # Add center coordinates of Tail, Handle, Tip - x and y: \n",
    "        # List of javelin parts\n",
    "        parts = [\"Tip\", \"Handle\", \"Tail\"]\n",
    "        missing_parts = []\n",
    "        \n",
    "        # Add columns, fill with NaN if missing\n",
    "        for part in parts:\n",
    "            x_col = f\"{part}_center_x\"\n",
    "            y_col = f\"{part}_center_y\"\n",
    "            if x_col not in plot_df.columns or y_col not in plot_df.columns:\n",
    "                missing_parts.append(part)\n",
    "            coords_df[x_col] = plot_df.get(x_col, pd.Series([np.nan]*len(plot_df))).values\n",
    "            coords_df[y_col] = plot_df.get(y_col, pd.Series([np.nan]*len(plot_df))).values\n",
    "\n",
    "        for part in parts:\n",
    "            x_col = f\"{part}_center_x\"\n",
    "            y_col = f\"{part}_center_y\"\n",
    "            for col in [x_col, y_col]:\n",
    "                if col in coords_df.columns:\n",
    "                    coords_df[col] = pd.Series(coords_df[col]).interpolate(method='linear', limit_direction='both')\n",
    "        \n",
    "        if len(missing_parts) == len(parts):\n",
    "            print(f\"⚠️ Warning: ALL javelin parts (Tip, Handle, Tail) missing in {session_name} (will fill with NaN).\")\n",
    "        \n",
    "        # --- only compute center if at least one point is present ---\n",
    "        def mean_if_at_least_one(row, cols):\n",
    "            values = row[cols].values\n",
    "            not_nan = np.isfinite(values)\n",
    "            if np.sum(not_nan) >= 1:\n",
    "                return np.nanmean(values)\n",
    "            else:\n",
    "                return np.nan\n",
    "        \n",
    "        x_cols = [f\"{part}_center_x\" for part in parts]\n",
    "        y_cols = [f\"{part}_center_y\" for part in parts]\n",
    "        \n",
    "        coords_df[\"javelin_center_x\"] = coords_df.apply(lambda row: mean_if_at_least_one(row, x_cols), axis=1)\n",
    "        coords_df[\"javelin_center_y\"] = coords_df.apply(lambda row: mean_if_at_least_one(row, y_cols), axis=1)\n",
    "        \n",
    "        # Distance from javelin center to wrists (same as before)\n",
    "        coords_df[\"dist_javelin_to_right_wrist\"] = np.sqrt(\n",
    "            (coords_df[\"javelin_center_x\"] - coords_df[\"right_wrist_x\"])**2 +\n",
    "            (coords_df[\"javelin_center_y\"] - coords_df[\"right_wrist_y\"])**2\n",
    "        )\n",
    "        coords_df[\"dist_javelin_to_left_wrist\"] = np.sqrt(\n",
    "            (coords_df[\"javelin_center_x\"] - coords_df[\"left_wrist_x\"])**2 +\n",
    "            (coords_df[\"javelin_center_y\"] - coords_df[\"left_wrist_y\"])**2\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Find instant when javelin leaves the hand:     \n",
    "        # First derivate to get the sharp increase in javelin to wrist:\n",
    "        left_signal  = coords_df[\"dist_javelin_to_left_wrist\"].values\n",
    "        right_signal = coords_df[\"dist_javelin_to_right_wrist\"].values\n",
    "        \n",
    "        left_deriv  = np.diff(left_signal, prepend=left_signal[0])\n",
    "        right_deriv = np.diff(right_signal, prepend=right_signal[0])\n",
    "        \n",
    "        \n",
    "        left_sustained_indices  = find_sustained_increases(\n",
    "            left_signal, left_deriv, threshold=THRESHOLD, min_sustain=min_sustain, min_delta=MIN_DELTA)\n",
    "        right_sustained_indices = find_sustained_increases(\n",
    "            right_signal, right_deriv, threshold=THRESHOLD, min_sustain=min_sustain, min_delta=MIN_DELTA)\n",
    "        \n",
    "        \n",
    "        release_indices = []\n",
    "        if len(left_sustained_indices) > 0 and len(right_sustained_indices) > 0:\n",
    "            a = left_sustained_indices[0]\n",
    "            b = right_sustained_indices[0]\n",
    "            release_idx = int(np.round((a + b) / 2))\n",
    "        elif len(left_sustained_indices) > 0:\n",
    "            release_idx = left_sustained_indices[0]\n",
    "        elif len(right_sustained_indices) > 0:\n",
    "            release_idx = right_sustained_indices[0]\n",
    "        else:\n",
    "            release_idx = None\n",
    "        \n",
    "        if release_idx is None:\n",
    "            print(f\"No release event detected for {session_name} / person {person_id}. Skipping.\")\n",
    "            continue\n",
    "                \n",
    "            \n",
    "        \n",
    "        # Calculate slope for both hips\n",
    "        x = np.arange(len(coords_df))  # Frame indices\n",
    "        \n",
    "        # Mean hip x for each frame (averaging left and right hip)\n",
    "        hip_x_mean = (coords_df[\"left_hip_x\"] + coords_df[\"right_hip_x\"]) / 2\n",
    "        \n",
    "        # Fit a line: slope tells direction\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, hip_x_mean)\n",
    "        \n",
    "        if slope > 0:\n",
    "            direction = \"to_Right\"\n",
    "        elif slope < 0:\n",
    "            direction = \"to_Left\"\n",
    "        else:\n",
    "            direction = \"No Movement\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate hip to ankle distance: \n",
    "        # --- Step 1: Prepare signals ---\n",
    "        coords_df[\"left_ankle_rel_x\"] = coords_df[\"left_hip_x\"] - coords_df[\"left_ankle_x\"]\n",
    "        coords_df[\"right_ankle_rel_x\"] = coords_df[\"right_hip_x\"] - coords_df[\"right_ankle_x\"]\n",
    "        \n",
    "        left_diff = coords_df[\"left_ankle_rel_x\"].values\n",
    "        right_diff = coords_df[\"right_ankle_rel_x\"].values\n",
    "        \n",
    "        DISTANCE = int(np.round(DISTANCE_MS * fps / 1000))\n",
    "        MAX_SHIFT_FRAMES = int(np.round(MAX_SHIFT_MS * fps / 1000))  # max shift in frames\n",
    "        \n",
    "        # --- Step 2: Find extrema in horizontal distance ---\n",
    "        if slope > 0:\n",
    "            left_extrema, _ = find_peaks(-left_diff, distance=DISTANCE, prominence=PROMINENCE)\n",
    "            right_extrema, _ = find_peaks(-right_diff, distance=DISTANCE, prominence=PROMINENCE)\n",
    "            extrema_label = \"Minima (before release)\"\n",
    "        elif slope < 0:\n",
    "            left_extrema, _ = find_peaks(left_diff, distance=DISTANCE, prominence=PROMINENCE)\n",
    "            right_extrema, _ = find_peaks(right_diff, distance=DISTANCE, prominence=PROMINENCE)\n",
    "            extrema_label = \"Maxima (before release)\"\n",
    "        else:\n",
    "            left_extrema, right_extrema = np.array([]), np.array([])\n",
    "            extrema_label = \"No movement\"\n",
    "        \n",
    "        # --- Step 3: Filter to those before release ---\n",
    "        if release_idx is not None:\n",
    "            left_extrema_before = left_extrema[left_extrema < release_idx]\n",
    "            right_extrema_before = right_extrema[right_extrema < release_idx]\n",
    "        else:\n",
    "            left_extrema_before, right_extrema_before = [], []\n",
    "        \n",
    "        # --- Step 4: Refine using ankle_y minima ---\n",
    "        left_refined = refine_to_next_ankle_y_maximum(\n",
    "            coords_df, left_extrema_before, side=\"left\", fps=fps,\n",
    "            MAX_SHIFT_MS=MAX_SHIFT_MS, Y_PROMINENCE=Y_PROMINENCE\n",
    "        )\n",
    "        right_refined = refine_to_next_ankle_y_maximum(\n",
    "            coords_df, right_extrema_before, side=\"right\", fps=fps,\n",
    "            MAX_SHIFT_MS=MAX_SHIFT_MS, Y_PROMINENCE=Y_PROMINENCE\n",
    "        )           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Calculations of joint angles:\n",
    "        \n",
    "        coords_df[\"elbow_l\"] = coords_df.apply(\n",
    "            lambda row: calculate_angle(row[\"left_wrist_x\"], row[\"left_wrist_y\"],\n",
    "                                         row[\"left_elbow_x\"], row[\"left_elbow_y\"],\n",
    "                                         row[\"left_shoulder_x\"], row[\"left_shoulder_y\"]), axis=1)\n",
    "        \n",
    "        coords_df[\"elbow_r\"] = coords_df.apply(\n",
    "            lambda row: calculate_angle(row[\"right_wrist_x\"], row[\"right_wrist_y\"],\n",
    "                                         row[\"right_elbow_x\"], row[\"right_elbow_y\"],\n",
    "                                         row[\"right_shoulder_x\"], row[\"right_shoulder_y\"]), axis=1)\n",
    "        \n",
    "        coords_df[\"knee_l\"] = coords_df.apply(\n",
    "            lambda row: calculate_angle(row[\"left_ankle_x\"], row[\"left_ankle_y\"],\n",
    "                                         row[\"left_knee_x\"], row[\"left_knee_y\"],\n",
    "                                         row[\"left_hip_x\"], row[\"left_hip_y\"]), axis=1)\n",
    "        \n",
    "        coords_df[\"knee_r\"] = coords_df.apply(\n",
    "            lambda row: calculate_angle(row[\"right_ankle_x\"], row[\"right_ankle_y\"],\n",
    "                                         row[\"right_knee_x\"], row[\"right_knee_y\"],\n",
    "                                         row[\"right_hip_x\"], row[\"right_hip_y\"]), axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate stride length: \n",
    "        # leg length: \n",
    "        leg_lengths_px = []\n",
    "        for i, row in coords_df.iterrows():\n",
    "            dists = []\n",
    "            if row['knee_r'] > 170:\n",
    "                dx_r = abs(row['right_hip_x'] - row['right_ankle_x'])\n",
    "                dy_r = abs(row['right_hip_y'] - row['right_ankle_y'])\n",
    "                d_r = np.sqrt(dx_r**2 + dy_r**2)\n",
    "                dists.append(d_r)\n",
    "            if row['knee_l'] > 170:\n",
    "                dx_l = abs(row['left_hip_x'] - row['left_ankle_x'])\n",
    "                dy_l = abs(row['left_hip_y'] - row['left_ankle_y'])\n",
    "                d_l = np.sqrt(dx_l**2 + dy_l**2)\n",
    "                dists.append(d_l)\n",
    "            if dists:\n",
    "                leg_lengths_px.append(np.mean(dists))\n",
    "        leg_length_px = np.nanmedian(leg_lengths_px)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # 1. Gather events (frame idx, x, y, side)\n",
    "        contacts = []\n",
    "        for idx in left_refined:\n",
    "            contacts.append((idx, coords_df.loc[idx, 'left_ankle_x'], coords_df.loc[idx, 'left_ankle_y'], 'L'))\n",
    "        for idx in right_refined:\n",
    "            contacts.append((idx, coords_df.loc[idx, 'right_ankle_x'], coords_df.loc[idx, 'right_ankle_y'], 'R'))\n",
    "                \n",
    "        # 2. Sort by frame index (time)\n",
    "        contacts.sort(key=lambda x: x[0])  # ascending by frame/time\n",
    "        \n",
    "        # 3. Only keep those before release, as above (already done if you used *_before arrays)\n",
    "        # Optional: Go backwards from last before release\n",
    "        contacts = [c for c in contacts if c[0] < release_idx]\n",
    "        \n",
    "        # 4. Calculate all steps before release, regardless of alternation\n",
    "        step_events = []\n",
    "        step_lengths_px = []\n",
    "        step_types = []\n",
    "        \n",
    "        for i in range(1, len(contacts)):  # forwards: earliest to latest\n",
    "            idx_prev, x_prev, y_prev, side_prev = contacts[i-1]\n",
    "            idx, x, y, side = contacts[i]\n",
    "            step_length = np.sqrt((x - x_prev)**2 + (y - y_prev)**2)\n",
    "            step_lengths_px.append(step_length)\n",
    "            ratio = step_length / leg_length_px if leg_length_px else np.nan\n",
    "            step_types.append(\"short\" if ratio < STEP_RATIO else \"long\")\n",
    "            step_events.append({\n",
    "                \"from_frame\": int(idx_prev),\n",
    "                \"to_frame\": int(idx),\n",
    "                \"from_side\": side_prev,\n",
    "                \"to_side\": side,\n",
    "                \"step_length_px\": float(step_length),\n",
    "                \"leg_length_px\": float(leg_length_px),\n",
    "                \"step_length/leg_length\": float(ratio),\n",
    "                \"type\": \"short\" if ratio < 1 else \"long\"\n",
    "            })\n",
    "        \n",
    "        # Sequence of all foot sides before release\n",
    "        step_sequence = [c[3] for c in contacts]\n",
    "\n",
    "\n",
    "        stride_pairs = []\n",
    "        for i in range(1, len(step_events)):\n",
    "            prev = step_events[i-1]\n",
    "            curr = step_events[i]\n",
    "            if prev[\"to_side\"] != curr[\"to_side\"]:  # alternation (e.g., L to R or R to L)\n",
    "                stride_pairs.append((prev[\"to_frame\"], curr[\"to_frame\"], prev[\"to_side\"], curr[\"to_side\"]))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "        # Did the student stop before release?\n",
    "        # --- Detect steps after release within a restricted time window ---\n",
    "        # We only count steps that happen shortly after the release event, not later during walking.\n",
    "        # Adjust `time_window_ms` to set the window (e.g., 400–1200 ms).\n",
    "        frames_window = int(np.ceil((time_window_ms / 1000) * fps))\n",
    "        \n",
    "        # Gather all detected foot contact indices (across both sides, all steps)\n",
    "        all_contact_indices = np.sort(np.concatenate([left_refined, right_refined]))\n",
    "        \n",
    "        def steps_after_release_within_window(all_contact_indices, release_idx, frames_window):\n",
    "            \"\"\"Return indices of steps occurring after release within a specific window.\"\"\"\n",
    "            post_release = all_contact_indices[all_contact_indices > release_idx]\n",
    "            return [int(idx) for idx in post_release if (idx - release_idx) <= frames_window]\n",
    "        \n",
    "        if release_idx is not None:\n",
    "            post_release_indices_in_window = steps_after_release_within_window(all_contact_indices, release_idx, frames_window)\n",
    "            if len(post_release_indices_in_window) > 0:\n",
    "                criterion_release_before_stop = False  # At least one step in window: student did NOT stop immediately after release\n",
    "                first_post_release_idx = post_release_indices_in_window[0]\n",
    "            else:\n",
    "                criterion_release_before_stop = True   # No step in window: student stopped after release\n",
    "                first_post_release_idx = None\n",
    "        else:\n",
    "            criterion_release_before_stop = None\n",
    "            first_post_release_idx = None\n",
    "        \n",
    "        \n",
    "        if first_post_release_idx is not None:\n",
    "            first_post_release_ms = (first_post_release_idx - release_idx) * 1000 / fps\n",
    "        else:\n",
    "            first_post_release_ms = None\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # --- Deceleration Detection: Is there a \"strong stop\" before release? ---    \n",
    "        # Safe defaults in case of early exit\n",
    "        vel_before = np.nan\n",
    "        vel_stop = np.nan\n",
    "        ratio = np.nan\n",
    "        strong_stop = None\n",
    "        stop_accel_value = None\n",
    "        stop_vel_after = None\n",
    "        \n",
    "        # Only calculate if release_idx is valid\n",
    "        if release_idx is not None:\n",
    "            coords_df[\"mean_hip_x\"] = (coords_df[\"left_hip_x\"] + coords_df[\"right_hip_x\"]) / 2\n",
    "        \n",
    "            # Velocity per frame (pixels/frame)\n",
    "            coords_df[\"mean_hip_x_vel\"] = coords_df[\"mean_hip_x\"].diff().fillna(0)\n",
    "            # Convert to velocity in pixels/sec\n",
    "            coords_df[\"mean_hip_x_vel\"] *= fps\n",
    "        \n",
    "            # Frame indices for windows\n",
    "            onset_offset_frames = int(np.ceil(ONSET_OFFSET_MS / 1000 * fps))\n",
    "            stop_win_frames = int(STOP_WIN_MS / 1000 * fps)\n",
    "        \n",
    "            # Indices for stop window (500 ms before release up to release)\n",
    "            idx_stop_win_start = max(onset_offset_frames, release_idx - stop_win_frames)\n",
    "            idx_stop_win_end = release_idx + 1  # include release frame\n",
    "        \n",
    "            # Indices for reference window (max 2.5s before stop window, starting at 150 ms after onset)\n",
    "            idx_runup_end = idx_stop_win_start\n",
    "            idx_runup_start = max(onset_offset_frames, idx_runup_end - int(WINDOW_BEFORE_RELEASE_MS / 1000 * fps))\n",
    "        \n",
    "            # Use mean hip x velocity series\n",
    "            hip_vel_series = coords_df[\"mean_hip_x_vel\"].values\n",
    "        \n",
    "            # Calculate mean velocities in the windows\n",
    "            vel_before = np.abs(hip_vel_series[idx_runup_start:idx_runup_end]).mean() if idx_runup_end > idx_runup_start else np.nan\n",
    "            vel_stop   = np.abs(hip_vel_series[idx_stop_win_start:idx_stop_win_end]).mean() if idx_stop_win_end > idx_stop_win_start else np.nan\n",
    "        \n",
    "            # Stop ratio and criterion\n",
    "            ratio = vel_stop / vel_before if vel_before > 0 else np.nan\n",
    "            strong_stop = ratio < STOP_RATIO_THRESHOLD if not np.isnan(ratio) else None\n",
    "        \n",
    "            # --- Additional: Compute hip acceleration (stop_accel_value) and post-release velocity (stop_vel_after) ---\n",
    "            # Hip acceleration (pixels/sec²)\n",
    "            hip_acc_series = np.diff(hip_vel_series, prepend=hip_vel_series[0]) * fps\n",
    "        \n",
    "            # Minimum acceleration (strongest deceleration) in stop window\n",
    "            if idx_stop_win_end > idx_stop_win_start:\n",
    "                stop_accel_value = np.nanmin(hip_acc_series[idx_stop_win_start:idx_stop_win_end])\n",
    "            else:\n",
    "                stop_accel_value = None\n",
    "        \n",
    "            # Mean hip velocity in window after release (e.g., next 200 ms)\n",
    "            POST_WIN_MS = 200\n",
    "            post_win_frames = int(np.ceil(POST_WIN_MS / 1000 * fps))\n",
    "            idx_post_win_start = release_idx + 1\n",
    "            idx_post_win_end = min(len(hip_vel_series), release_idx + 1 + post_win_frames)\n",
    "        \n",
    "            if idx_post_win_end > idx_post_win_start:\n",
    "                stop_vel_after = np.abs(hip_vel_series[idx_post_win_start:idx_post_win_end]).mean()\n",
    "            else:\n",
    "                stop_vel_after = None\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculation for assessing if elbow was pointing in the throwing direction\n",
    "        # PRE window: exactly 500 ms\n",
    "        \n",
    "        n_pre_frames = int(np.round(0.500 * fps))\n",
    "        idx_pre_start = max(0, release_idx - n_pre_frames + 1)\n",
    "        idx_pre_end = release_idx + 1\n",
    "        pre_window = coords_df.iloc[idx_pre_start:idx_pre_end]\n",
    "        \n",
    "        # POST window: exactly 500 ms\n",
    "        n_post_frames = int(np.round(0.500 * fps))\n",
    "        idx_post_start = release_idx\n",
    "        idx_post_end = min(len(coords_df), release_idx + n_post_frames)\n",
    "        post_window = coords_df.iloc[idx_post_start:idx_post_end]\n",
    "        \n",
    "        if direction == \"to_Right\":\n",
    "            throwing_side = \"right\"\n",
    "        else:\n",
    "            throwing_side = \"left\"\n",
    "        \n",
    "        elbow_x_col = f\"{throwing_side}_elbow_x\"\n",
    "        wrist_x_col = f\"{throwing_side}_wrist_x\"\n",
    "        elbow_angle_col = f\"elbow_{throwing_side[0]}\"  # 'elbow_r' or 'elbow_l'\n",
    "        \n",
    "        \n",
    "        # 1. Elbow ahead of wrist (20%+)\n",
    "        if direction == \"to_Right\":\n",
    "            ahead_mask = pre_window[elbow_x_col] > pre_window[wrist_x_col]\n",
    "        else:\n",
    "            ahead_mask = pre_window[elbow_x_col] < pre_window[wrist_x_col]\n",
    "        \n",
    "        frac_ahead = np.mean(ahead_mask)\n",
    "        criterion_1 = frac_ahead >= 0.20\n",
    "        \n",
    "        # 2. Min elbow angle <90° in at least 3% of frames\n",
    "        frac_min_angle = np.mean(pre_window[elbow_angle_col] < 90)\n",
    "        criterion_2 = frac_min_angle >= 0.03\n",
    "        # For min elbow angle < 90° (pre-release)\n",
    "        num_frames_min_angle = np.sum(pre_window[elbow_angle_col] < 90)\n",
    "        duration_min_angle_ms = num_frames_min_angle * (1000 / fps)\n",
    "        \n",
    "        # 3. Max elbow angle >150° in at least 3% of frames after release\n",
    "        frac_max_angle = np.mean(post_window[elbow_angle_col] > 150)\n",
    "        criterion_3 = frac_max_angle >= 0.03\n",
    "        # For max elbow angle > 150° (post-release)\n",
    "        num_frames_max_angle = np.sum(post_window[elbow_angle_col] > 150)\n",
    "        duration_max_angle_ms = num_frames_max_angle * (1000 / fps)\n",
    "        \n",
    "        # 4. Positive slope of elbow angle before release \n",
    "        slope_win = int(0.300 * fps)\n",
    "        idx_slope_start = max(0, release_idx - slope_win)\n",
    "        idx_slope_end = release_idx + 1\n",
    "        \n",
    "        elbow_angles_slope = coords_df[elbow_angle_col].iloc[idx_slope_start:idx_slope_end].values\n",
    "        x_vals = np.arange(len(elbow_angles_slope))\n",
    "        \n",
    "        if len(elbow_angles_slope) > 1:\n",
    "            slope_val, _, _, _, _ = linregress(x_vals, elbow_angles_slope)\n",
    "            criterion_4 = slope_val > 0\n",
    "        else:\n",
    "            slope_val = np.nan\n",
    "            criterion_4 = False\n",
    "        \n",
    "        # For min in pre-window\n",
    "        tol = 5  # or whatever you use for float tolerance\n",
    "        min_val = np.nanmin(pre_window[elbow_angle_col])\n",
    "        min_mask = np.abs(pre_window[elbow_angle_col] - min_val) < tol\n",
    "        labeled, n_features = label(min_mask)\n",
    "        durations = [np.sum(labeled == i) for i in range(1, n_features + 1)]\n",
    "        if any(d >= 3 for d in durations):\n",
    "            min_angle_valid = min_val\n",
    "        else:\n",
    "            min_angle_valid = np.nan\n",
    "        \n",
    "        # For max in post-window\n",
    "        max_val = np.nanmax(post_window[elbow_angle_col])\n",
    "        max_mask = np.abs(post_window[elbow_angle_col] - max_val) < tol\n",
    "        labeled, n_features = label(max_mask)\n",
    "        durations = [np.sum(labeled == i) for i in range(1, n_features + 1)]\n",
    "        if any(d >= 3 for d in durations):\n",
    "            max_angle_valid = max_val\n",
    "        else:\n",
    "            max_angle_valid = np.nan\n",
    "        \n",
    "        \n",
    "        num_frames_ahead = np.sum(ahead_mask)\n",
    "        \n",
    "    \n",
    "        # Elbow outstretched AND behind shoulder\n",
    "        \n",
    "        # Determine correct elbow and shoulder columns based on throwing side\n",
    "        if direction == \"to_Right\":\n",
    "            throwing_side = \"right\"\n",
    "            elbow_x_col = \"right_elbow_x\"\n",
    "            shoulder_x_col = \"right_shoulder_x\"\n",
    "            elbow_angle_col = \"elbow_r\"\n",
    "        elif direction == \"to_Left\":\n",
    "            throwing_side = \"left\"\n",
    "            elbow_x_col = \"left_elbow_x\"\n",
    "            shoulder_x_col = \"left_shoulder_x\"\n",
    "            elbow_angle_col = \"elbow_l\"\n",
    "        else:\n",
    "            raise ValueError(\"Unknown throwing direction!\")\n",
    "        \n",
    "        \n",
    "  \n",
    "        \n",
    "        # Calculate frame indices\n",
    "        onset_offset_frames = int(np.ceil(ONSET_OFFSET_MS / 1000 * fps))\n",
    "        offset_frames = int(np.round(OFFSET_BEFORE_RELEASE_MS / 1000 * fps))\n",
    "        idx_win_end = max(onset_offset_frames, release_idx - offset_frames + 1)\n",
    "        idx_win_start = max(onset_offset_frames, idx_win_end - int(WINDOW_BEFORE_RELEASE_MS / 1000 * fps))\n",
    "        \n",
    "        elbow_series = coords_df[elbow_angle_col].iloc[idx_win_start:idx_win_end].values\n",
    "        elbow_x_series = coords_df[elbow_x_col].iloc[idx_win_start:idx_win_end].values\n",
    "        shoulder_x_series = coords_df[shoulder_x_col].iloc[idx_win_start:idx_win_end].values\n",
    "        \n",
    "        # 1. Frames with sustained extension AND elbow behind shoulder\n",
    "        above = elbow_series > THRESHOLD_ANGLE\n",
    "        if direction == \"to_Right\":\n",
    "            behind = elbow_x_series < shoulder_x_series\n",
    "        elif direction == \"to_Left\":\n",
    "            behind = elbow_x_series > shoulder_x_series\n",
    "        else:\n",
    "            behind = np.ones_like(elbow_x_series, dtype=bool)  # fallback: don't restrict\n",
    "        \n",
    "        above_and_behind = above & behind\n",
    "        num_above_and_behind = np.sum(above_and_behind)\n",
    "        duration_above_and_behind_ms = num_above_and_behind * 1000 / fps\n",
    "        sustained_extension_and_behind = duration_above_and_behind_ms >= REQUIRED_ABOVE_ANGLE_MS\n",
    "\n",
    "        if sustained_extension_and_behind:\n",
    "            above_indices = np.where(above_and_behind)[0]\n",
    "            sustained_start_idx = idx_win_start + above_indices[0]\n",
    "            sustained_end_idx = idx_win_start + above_indices[-1]\n",
    "        else:\n",
    "            sustained_start_idx = sustained_end_idx = np.nan\n",
    "        \n",
    "        # 2. Maximum angle reached (descriptive, not a pass/fail)\n",
    "        max_angle = np.nanmax(elbow_series)\n",
    "        \n",
    "        # 3. (Optional/Descriptive) Did max angle persist for at least N frames?\n",
    "        from scipy.ndimage import label\n",
    "        tolerance = 5\n",
    "        max_mask = np.abs(elbow_series - max_angle) < tolerance\n",
    "        labeled, n_features = label(max_mask)\n",
    "        max_durations = [np.sum(labeled == i) for i in range(1, n_features + 1)]\n",
    "        max_angle_streak = max(max_durations) if max_durations else 0\n",
    "        max_angle_streak_ok = max_angle_streak >= MIN_MAX_DURATION_FRAMES\n",
    "\n",
    "\n",
    "        if release_idx is None:\n",
    "            print(f\"No release event detected for {session_name} / person {person_id}. Skipping.\")\n",
    "            continue\n",
    "        summary_row = {\n",
    "            \"session\": session_name,\n",
    "            \"person_id\": person_id,\n",
    "            \"school\": school, \n",
    "            \"class_id\": class_id,\n",
    "            \"condition\": condition,\n",
    "            \"subject_id\": subj_id,\n",
    "            \"throw_number\": throw_nr,\n",
    "            \"release_idx\": int(release_idx),\n",
    "            \"direction\": direction,\n",
    "            \"fps\": fps, \n",
    "            \"slope\": float(slope),\n",
    "            \"leg_length_px\": float(leg_length_px),\n",
    "            \"num_steps\": len(step_events),\n",
    "            \"step_from_frames\": [x[\"from_frame\"] for x in step_events],\n",
    "            \"step_to_frames\": [x[\"to_frame\"] for x in step_events],\n",
    "            \"step_from_sides\": [x[\"from_side\"] for x in step_events],\n",
    "            \"step_to_sides\": [x[\"to_side\"] for x in step_events],\n",
    "            \"step_lengths_px\": [x[\"step_length_px\"] for x in step_events],\n",
    "            \"step_types\": [x[\"type\"] for x in step_events],\n",
    "            \"step_sequence\": [x[\"to_side\"] for x in step_events], \n",
    "            # Real event-based kinematic fields (replace with your calculated variables)\n",
    "            \"throwing_side\": throwing_side,\n",
    "            \"elbow_ahead_of_wrist_ms_pre\": float(num_frames_ahead * 1000 / fps),\n",
    "            \"criterion_1_elbow_ahead\": bool(criterion_1),\n",
    "            \"elbow_below_90_ms_pre\": float(duration_min_angle_ms),\n",
    "            \"criterion_2_min_elbow\": bool(criterion_2),\n",
    "            \"elbow_above_150_ms_post\": float(duration_max_angle_ms),\n",
    "            \"criterion_3_max_elbow\": bool(criterion_3),\n",
    "            \"elbow_angle_slope\": float(slope_val) if not np.isnan(slope_val) else np.nan,\n",
    "            \"criterion_4_positive_slope\": bool(criterion_4),\n",
    "            \"min_elbow_angle_pre\": float(min_angle_valid),\n",
    "            \"max_elbow_angle_post\": float(max_angle_valid),\n",
    "            \"max_elbow_angle_pre_release\": float(max_angle),\n",
    "            \"max_angle_streak_frames\": int(max_angle_streak),\n",
    "            \"sustained_extension\": bool(sustained_extension_and_behind),\n",
    "            \"sustained_extension_start_idx\": sustained_start_idx,\n",
    "            \"sustained_extension_end_idx\": sustained_end_idx,\n",
    "            \"true_stop_after_release\": bool(criterion_release_before_stop),\n",
    "            \"first_post_release_idx\": int(first_post_release_idx) if first_post_release_idx is not None else None,\n",
    "            \"first_post_release_ms\": float(first_post_release_ms) if first_post_release_ms is not None else None,\n",
    "            \"strong_stop\": bool(strong_stop) if strong_stop is not None else None,\n",
    "            \"vel_before\": float(vel_before) if not np.isnan(vel_before) else None,\n",
    "            \"vel_stop\": float(vel_stop) if not np.isnan(vel_stop) else None,\n",
    "            \"stop_ratio\": float(ratio) if not np.isnan(ratio) else None,\n",
    "            \"min_hip_acc\": float(stop_accel_value) if stop_accel_value is not None else None,\n",
    "            \"stop_vel_after\": float(stop_vel_after) if stop_vel_after is not None else None,\n",
    "            \"FPS\": fps, \n",
    "            \n",
    "        }\n",
    "        all_results.append(summary_row)\n",
    "    \n",
    "\n",
    "summary_df = pd.DataFrame(all_results)\n",
    "summary_df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Saved summary to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc2462-43c4-4bf1-9c6d-ce85bde0aaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
